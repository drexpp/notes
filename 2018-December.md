November 2018
==========

Tech
----

### Adversarial examples [Ian Goodfellow lecture](https://www.youtube.com/watch?v=CIfsB_EYsVI)

  -  (**Note**) Multiple linear layers can be equivalent to a single linear layer. As the other answers have said, a nonlinear activation function allows nonlinear classification. Saying that a classifier is nonlinear means that it has a nonlinear decision boundary. The decision boundary is a surface that separates the classes; the classifier will predict one class for all points on one side of the decision boundary, and another class for all points on the other side. [Second reply](https://stats.stackexchange.com/questions/222639/what-makes-neural-networks-a-nonlinear-classification-model)
  
  - A different variety of linear models can be attacked by adversarial examples, such as:
    - Neural networks
    - Linear models:
      - Logistic regression
      - Softmax regression
      - SVMs
    - Decision trees
    - Nearest neighbors
  
